1) Consider running the naive version with the following command line:

./transpose -n 14 -b 16 -naive -time

What are the number of:
threads per block: 
size of the grid (x by x): 
total number of blocks: 
total number of threads: 

2) Consider running the tiled version with the following command line:

./transpose -n 14 -b 16 -t 2 -tiled -time

What are the number of:
threads per block: 
size of the grid (x by x): 
total number of blocks: 
total number of threads: 

3) Now, run the two command lines indicated above. You should see that
the tiled version performs slightly faster than the naive versions 
(this should be the general trend although timing on the CUDA machine 
can vary widely).  Explain why the tiled version tends to provide 
higher performance. Take a look at the "7.5 Optimizing for CUDA"
slides.


4) Report the timing for running the following command lines:
./transpose -n 14 -b 16 -t 2  -tiled -time
./transpose -n 14 -b 16 -t 4  -tiled -time
./transpose -n 14 -b 16 -t 8  -tiled -time


5) For problem 4), you should have seen that the performance decreased with increasing
tile size.  Why?


6) Now, run these two command lines and report their results:
./transpose -n 14 -b 16 -t 4  -tiled -time
./transpose -n 14 -b 16 -opttiled -time


7) You should see that the opttiled version in provides better performance than the
tiled version in question 6. (This is in general. Individual runs can vary widely.)
Explain why. Hint: think about what is happening in these two different
versions in terms of how memory is accessed.  For the tiled version, 
threads in lockstep will read an element and write it to the destination. 
It will do this 16 times. For the opttiled version, threads in lockstep will 
read 16 elements by performing 8 reads, transpose those in the local array, 
and write the 16 elements by performing 8 writes to the destination array.
(Chapter 3 can help you come up with a thorough answer to this.)


8) Why can't shared memory be used in the opttiled implementation?

9) Finally test your code with these parameters to make sure you
don't access outside of the matrix array. Report their timings.

./transpose -n 4 -b 32 -naive -time
./transpose -n 4 -b 32 -t 2 -tiled -time
./transpose -n 4 -b 32 -opttiled -time
